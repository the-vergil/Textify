{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cbgwZWWfWpp"
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPAQOszvP7xT"
   },
   "source": [
    "## Step 1 : Install and import dependencies\n",
    "---\n",
    "    Install torch (get the link from PyTorch website)\n",
    "    Install Numpy\n",
    "    Install Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAb77yZ9fzMG",
    "outputId": "c9d753b0-8fdd-480d-8705-7159086a1981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pafL7Li0jyXW",
    "outputId": "96b4a0db-a665-44b1-a792-b0cdae783b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "81Hua0OVQZUM"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Rw-TfjHTRpF"
   },
   "source": [
    "## Step 2 : Instantiate model\n",
    "---\n",
    "### Tokenizer\n",
    "    Tokenizers are used to convert raw text into numbers\n",
    "\n",
    "### AutoModelFor\n",
    "    AutoModelFor lets you load a pretrained model for a given task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZJ2zXwtqSNnE"
   },
   "outputs": [],
   "source": [
    "# Instantiate AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Instantiate AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wlaGs_EVfc2"
   },
   "source": [
    "## Step 3 : Encode and Calculate Sentiment\n",
    "---\n",
    "    Create a function that takes an input string/text and return its sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bXRp0lwAXyTK"
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(input_string) :\n",
    "  # encode the input string\n",
    "  tokens = tokenizer.encode(input_string[:512], return_tensors=\"pt\")\n",
    "  \n",
    "  # output the tokens\n",
    "  print(f\"Tokensized text : {tokens}\\n\")\n",
    "\n",
    "  # output the decoded text\n",
    "  print(f\"Decoded tokenized text : {tokenizer.decode(tokens[0])}\\n\")\n",
    "\n",
    "  # use the model to get the sentiment score array\n",
    "  result = model(tokens)\n",
    "\n",
    "  # output the score array\n",
    "  print(f\"Score : {result.logits}\\n\")\n",
    "\n",
    "  # output the max value as a final result\n",
    "  ans = int(torch.argmax(result.logits)) + 1\n",
    "  print(f\"Final Score : {ans} stars (on a scale of 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Pb7HwpPspeHk"
   },
   "outputs": [],
   "source": [
    "def sentiment_score(input_string) :\n",
    "  # encode the input string\n",
    "  tokens = tokenizer.encode(input_string[:512], return_tensors=\"pt\")\n",
    "\n",
    "  # use the model to get the sentiment score array\n",
    "  result = model(tokens)\n",
    "\n",
    "  # output the max value as a final result\n",
    "  ans = int(torch.argmax(result.logits)) + 1\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yv0jbO6lZ-9_",
    "outputId": "4cbe649f-72db-4019-8dcf-517f3aebc2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokensized text : tensor([[  101,   151, 11157, 10855,   117,   151, 10743,   112,   162, 11343,\n",
      "         13208, 10855,   119,   102]])\n",
      "\n",
      "Decoded tokenized text : [CLS] i love you, i can't live without you. [SEP]\n",
      "\n",
      "Score : tensor([[-1.8182, -2.1729, -1.1707,  0.8624,  3.3813]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Final Score : 5 stars (on a scale of 5)\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(\"I love you, I can't live without you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI3HsF4vamCW",
    "outputId": "f82fae39-b99d-42e9-b98a-2c1bdaabcc4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokensized text : tensor([[  101,   151, 18763, 11312,   112, 17361, 13362, 19508, 12590,   119,\n",
      "           102]])\n",
      "\n",
      "Decoded tokenized text : [CLS] i hope we'll never meet again. [SEP]\n",
      "\n",
      "Score : tensor([[-0.2748,  0.1177,  0.4230, -0.0332, -0.2835]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Final Score : 3 stars (on a scale of 5)\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(\"I hope we'll never meet again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu8d8xZ5Xu9c",
    "outputId": "52fd4946-c1b7-4657-876c-85241a8cd0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokensized text : tensor([[  101, 69557, 10855, 14693, 10574, 12677, 10203, 11111,   119,   102]])\n",
      "\n",
      "Decoded tokenized text : [CLS] maybe you should have died that day. [SEP]\n",
      "\n",
      "Score : tensor([[ 0.8251,  0.5463,  0.4002, -0.6007, -1.0558]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Final Score : 1 stars (on a scale of 5)\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(\"Maybe you should have died that day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx0a3uX8ptfb",
    "outputId": "4d01ec0b-082d-4b14-8a13-a6406063a327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score(\"I love you, I can't live without you.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uATT1Uu-rFH6"
   },
   "source": [
    "## Step 4 : Save the function for later use\n",
    "---\n",
    "    Use pickle to save sentiment_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "60FbDQrYasut"
   },
   "outputs": [],
   "source": [
    "pickle.dump(sentiment_score, open(\"sentiment_score.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp0zDiB3rS70"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
